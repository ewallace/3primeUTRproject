---
title: "tablePreparation"
output:
  html_notebook:
    error: no
    message: no
    toc: yes
    toc_depth: 4
    toc_float: yes
    warning: no
  pdf_document:
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

This Rnotebook covers the code used for preparing the [Genomic Expression Programs in the Response of Yeast Cells to Environmental Changes](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC15070/) (Gasch et al, 2000) dataset for downstream Motifs analysis (mainly MEME suite). The preparation processes mainly involve:

* table manipulation to create source expression table

* clustering to group gene with similar pattern 

* visualization of cluster by heatmap and GO-enrichment analyses to find biological meaning of the gene clusters


#table manipulation

Initially we intended to make the clustering results comparable with results from Gasch paper, therefore we decided to reproduce Gasch clustering or at least make the results as close as possible.

In the orginal paper, the authors clustered gene expression microarrya of wildtype yeast under 160 environmental stress conditions. And then present 142 of them in the article figure. To get similar results, these same data needs to be clustered first. However, the raw table deposited on the authors website contains all data (not only wildtype but also mutants) the ordering is differ from what presented in the paper

**what I did:**

* extract wildtype conditions

* extract the condition used in original paper's clustering (160 conditions)

* rearrage the table

* create table for figures (142 tables)

##**R packages**

Tidyverse, from my experience, is very well-rounded, all-in-one package for table manipulation. It covers many aspect of table manipulation such as filtering, merging and iterative operations. So using only this one is enough to cover all the works needed for table preparation.

Installation
```{r}
install.packages("tidyverse")
```
Library call
```{r}
library(tidyverse)
```

###Obtain dataset
download source table in .txt format from the gasch dataset page (http://genome-www.stanford.edu/yeast_stress/data/rawdata/complete_dataset.txt)
```{r}
gaschdata <- read_tsv("http://genome-www.stanford.edu/yeast_stress/data/rawdata/complete_dataset.txt")
```

###Extract clustered conditions

create temporary table to preserve the original copy, just in case we want to go back modifying the original table.
```{r}
gaschdata.tmp<-gaschdata
```

```{r echo=FALSE}
gaschdata.tmp[1:10,1:10]
```

Now, take a look at the NAME column:
```{r echo=FALSE}
gaschdata.tmp[1:10,2]
```
This colum contains important information such as uid, gene symbol. So we decide to divide this column into different columns.
From NAME to UID, SYMBOL, DESCRIPTION and SID. Even thought most of the downstream processes would need only a naked table (just UID and expression profiles), these data might be merged back for the analyses later on.

First, start with replacing missing genesymbol with NA using regex syntax. 

Judging by the looks of NAME column alone, it may seem to be well formatted. In reality, white space character has been used, making it hard to separate by tidyverse function. So, we will replace this one first.

* \\b=border of words
* {12,14} 12 and 14 white space 
```{r}
gaschdata.tmp$NAME<-sub("\\b {12,14}\\b", "   NA       ",gaschdata.tmp$NAME)
```
Then split NAME column one by one. Note that V3 column is splitted backward by using the position of character since SID are always 8-digits.
```{r}
gaschdata.tmp<-separate(gaschdata.tmp, col="NAME", into=c("UID", "V2"),sep=" {1,3}", extra="merge")
gaschdata.tmp<-separate(gaschdata.tmp, col="V2", into=c("SYMBOL", "V3"), extra="merge")
gaschdata.tmp<-separate(gaschdata.tmp, col="V3",into=c("DESCRIPTION","SID"),sep=-8)
```
Save the columns into separate table for later use.
```{r}
original_gene_info<-gaschdata.tmp[,2:5]
```
```{r echo=FALSE}
original_gene_info
```

```{r eval=FALSE, include=FALSE}
#UID entry check
UID_check<-tibble(UID1=gaschdata.tmp$UID, UID_from_NAME=original_gene_info$UID)
```

Next, the conditions. 
```{r}
colnames(gaschdata.tmp)[6:178]
```
The original table already provide well described column names, but we will shorten them to make them easier to work with. (Too long column names might get in the way during coding and analysis)

Simplify column names and then replace.
```{r}
new_column_name<-c("hs_05_rep1", "hs_10_rep1", "hs_15_rep1", "hs_20_rep1", "hs_30_rep1", "hs_40_rep1", "hs_60_rep1", "hs_80_rep1", 
"hs_00_rep2_1", "hs_00_rep2_2", "hs_00_rep2_3", "hs_05_rep2", "hs_15_rep2", "hs_30_rep2", "hs_60_rep2", 
"37t25_S_15", "37t25_S_30", "37t25_S_45", "37t25_S_60", "37t25_S_90", "hs_17t37", "hs_21t37", "hs_25t37", "hs_29t37", "hs_33t37", 
"29t33_05", "29t33_15", "29t33_30", "33v30_90",
"29_sorb_33_sorb_05", "29_sorb_33_sorb_15", "29_sorb_33_sorb_30", "29_sorb_33_NOsorb_05", "29_sorb_33_NOsorb_15", "29_sorb_33_NOsorb_30",
"const_h2o2_010", "const_h2o2_020", "const_h2o2_030", "const_h2o2_040", "const_h2o2_050", "const_h2o2_060", "const_h2o2_080", "const_h2o2_100","const_h2o2_120","const_h2o2_160",
"mena_010","mena_020","mena_030","mena_040","mena_050","mena_080","mena_105","mena_120","mena_160",
"ddt_005_rep1","ddt_015_rep1","ddt_030_rep1","ddt_045_rep1","ddt_060_rep1","ddt_090_rep1","ddt_120_rep1","ddt_180_rep1",
"ddt_000_rep2","ddt_015_rep2","ddt_030_rep2","ddt_060_rep2","ddt_120_rep2","ddt_240_rep2","ddt_480_rep2",
"diam_05","diam_10","diam_20","diam_30","diam_40","diam_50","diam_60","diam_90",
"sorb_005","sorb_015","sorb_030","sorb_045","sorb_060","sorb_090","sorb_120",
"hypo_05","hypo_15","hypo_30","hypo_45","hypo_60",
"steady_sorb",
"aa_strav_030","aa_strav_1h","aa_strav_2h","aa_strav_4h","aa_strav_6h",
"n_deplet_30","n_deplet_1h","n_deplet_2h","n_deplet_4h","n_deplet_8h","n_deplet_12h","n_deplet_1d","n_deplet_2d","n_deplet_3d","n_deplet_5d",
"diaux_00.0h","diaux_09.5h","diaux_11.5h","diaux_13.5h","diaux_15.5h","diaux_18.5h","diaux_20.5h",
"ypd_2h_rep2","ypd_4h_rep2","ypd_6h_rep2","ypd_8h_rep2","ypd_10h_rep2","ypd_12h_rep2","ypd_1d_rep2","ypd_2d_rep2","ypd_3d_rep2","ypd_5d_rep2",
"ypd_2h_rep1","ypd_4h_rep1","ypd_8h_rep1","ypd_12h_rep1","ypd_1d_rep1","ypd_2d_rep1","ypd_3d_rep1","ypd_5d_rep1","ypd_7d_rep1","ypd_13d_rep1","ypd_22d_rep1","ypd_28d_rep1",
"dby7286_37c","dby_msn2msn4_37c","dby_msn2msn4(real)_37c","dby_yap1_37c","dby_yap1_37c_rep",
"dby7286_0.3h2o2","dby_msn2msn4_0.32h2o2","dby_msn2msn4(real)_0.32h2o2","dby_yap1_0.3h2o2","dby_yap1_0.32h2o2",
"msn2_over","msn4_over","YAP1_over",
"yp_eth_rep1","yp_gal_rep1","yp_glu_rep1","yp_man_rep1","yp_raf_rep1","yp_suc_rep1",
"yp_eth_rep2","yp_fru_rep2","yp_gal_rep2","yp_glu_rep2","yp_man_rep2","yp_raf_rep2","yp_suc_rep2",
"17c_growth","21c_growth","25c_growth","29c_growth","37c_growth",
"15c_steady","17c_steady","21c_steady","25c_steady","29c_steady","33c_steady","36c_steady","36c_steady_rep")
colnames(gaschdata.tmp)[6:178]<-new_column_name
```

```{r}
new_column_name
```

###Create table for clustering

The original paper used only wildtype treatment for clustering. Therefore, we will select wildtype to reproduce the clustering results. 
160 non-mutant condition
```{r}
init_table_160<-gaschdata.tmp[,c(2,6:139,153:178)]
as.matrix(init_table_160[,-1])->init_table_160.mat
init_table_160$UID->rownames(init_table_160.mat)
```
```{r}
init_table_160
```


142 condtions
```{r}
init_table_142.mat<-init_table_160.mat[,-c(2,4,6,8:11,55,58,60,62,63,131:134,138,145)]
```
```{r}
init_table_142.mat
```

94 condtions
Extract column used in the original paper key figure. In this part, we replicated the calculation method for gene expression normalisation in the Gasch paper. To put it simply, in the conditions that has control condition reported, the treated condition will be subtracted by control condtion.
```{r}
#heatshocktimeseries
init_table_94.mat<-as.matrix(init_table_160.mat[,c(12:15)]-as.numeric(rowSums(init_table_160.mat[,c(9:11)],na.rm=TRUE)/3))
#heatshock temp series
init_table_94.mat<-as.matrix(cbind(init_table_94.mat,init_table_160.mat[,c(21:25)]))
#h2o2 and menadione time series
init_table_94.mat<-as.matrix(cbind(init_table_94.mat,init_table_160.mat[,c(36:54)]))
#ddt time series
init_table_94.mat<-as.matrix(cbind(init_table_94.mat,as.matrix(init_table_160.mat[,c(64:69)]-init_table_160.mat[,63])))
#diaminde, sorbital, aa stravation, nitrogen depletion, diauxic, and ypd time series
init_table_94.mat<-as.matrix(cbind(init_table_94.mat,init_table_160.mat[,c(70:84, 91:122)]))
#carbo series
init_table_94.mat<-as.matrix(cbind(init_table_94.mat,as.matrix(init_table_160.mat[,c(141,143,146,147,142)]-init_table_160.mat[,144])))
#steady state series
init_table_94.mat<-as.matrix(cbind(init_table_94.mat,as.matrix(init_table_160.mat[,c(153:157)]-init_table_160.mat[,158])))
init_table_94.mat<-as.matrix(cbind(init_table_94.mat,as.matrix(rowSums(init_table_160.mat[,c(159:160)])/2-init_table_160.mat[,158])))
colnames(init_table_94.mat)[length(colnames(init_table_94.mat))]<-"36c_steady"
```

```{r}
init_table_94.mat
```

After the raw tables are prepared, they will be used for clustering. 

Let's flashback a little bit. We cluster this expression microarray dataset because we want to group genes into clusters using their expresion patterns. The rationale behind this is that, 

* At this state of the project, we want to find regulators which respond to environmental stresses. 

* Our initial assumprion is that gene with same regulators will have the same expression pattern.

* So, we have to find the expression pattern (by clustering), in order to trace back to a regulator.

##CLUSTERING

**HybridHclust** package contains Eigen clustering in Eigen 1998 paper, to completely replicate the original result, we will also include this method.
```{r}
install.packages("hybridHclust")
```
```{r}
library(hybridHclust)
```


###Distance Matrix

Distance matrices are a base material for heirachical clustering. The matrices contain distant values of each row pair, which the calculation method can be specified by the user.

Method used in this work:

* **Pearson correlation** normally used for micrroarray analysis
* **Euclidean distance** for Ward clustering

####Create distance matrix

PEARSON
```{r}
table_142.pearson.dist<-as.dist(1-cor(t(init_table_142.mat), use="pairwise.complete.obs"))
```

EUCLIDEAN
```{r}
table_142.euclidean.dist<-dist(init_table_142.mat)
```

###Clustering

There is no strict criteria on how to select clustering method. And there are many factors to be considered such as the nature of data, shape of cluster, hardware requirement, etc. But the most important thing is the results should be meaningful biologically. So, we will use several clustering methods to cluster the dataset first and then throuroughly investigate the outcomes.

The outcomes from clustering using functions here are hclust ojects which stores information about the tree (dendrogram) produced by the clustering process.

UPGMA
```{r}
table_142.UPGMAclust<-hclust(table_142.pearson.dist, method="average")
```

WPGMA
```{r}
table_142.WPGMAclust<-hclust(table_142.pearson.dist, method="mcquitty")
```

WARD.D2
```{r}
table_142.WardD2clust<-hclust(table_142.euclidean.dist, method="ward.D2")
```

EisenCluster

This one is the same method as in the originalpaper. The package needs only raw table input, however, it is computationally demanding. Could take more than 6 hours to finish.
```{r}
table_142.eisenclust<-eisenCluster(init_table_142.mat, method="correlation", verbose = TRUE)
```

####Create cluster table
As mentioned earlier, hclust objects resulted from the previous step contain the clustered tree, but we have not gotten the actual clusters yet. The have to be chopped down into cluster by another function named cutree(). In this section, we will define the fuction that simplify cutree() and assign the cluster number to each gene (row). The output of this function is a new table containing gene names and their cluster number.

When the project is in progress, we did not know how many cluster we should use for downstream processes. So, the cutree function was iterated through a set of cluster number. For this fuction, we can set the maximum number of cluster. 

Define function
```{r}
assign_cluster<-function(hclust_object, minimum_cluster=1, maximum_cluster){
  for (i in minimum_cluster:maximum_cluster){
  
    col_name<-paste("cluster",i,sep="_")
    clustered.temp<-cutree(hclust_object, k=i)
    if(i==minimum_cluster){
    cluster_table<-data.frame(clustered.temp=as.factor(clustered.temp),row.names=rownames(init_table_94.mat))
  }else{
    cluster_table$clustered.temp<-as.factor(clustered.temp)
    }
    names(cluster_table)[names(cluster_table) == 'clustered.temp']<-col_name 
  }
  return(cluster_table)
}
```

```{r}
UPGMA.cluster_table<-assign_cluster(table_142.UPGMAclust,1,20)
head(UPGMA.cluster_table)
```
```{r}
WPGMA.cluster_table<-assign_cluster(table_142.WPGMAclust,1,20)
head(WPGMA.cluster_table)
```
```{r}
WardD2.cluster_table<-assign_cluster(table_142.WardD2clust,1,20)
head(WardD2.cluster_table)
```
```{r}
Eisen.cluster_table<-assign_cluster(table_142.eisenclust,1,20)
head(Eisen.cluster_table)
```

####heatmap for comparison

Flashback: We tried several clustering method because we wanted to find the suitable clustering for downstream process. In order to facilitated the comparison of tables with 6000+ rows, we use heatmap to visualise those tables. 

Please note that there are several factors included in selection process such as:

* clustering process -- unlike the previous publication, 'gene clusters' in this project were assigned computationally by using cutree function, not the biological knowledge. Sometimes resulted cluster might not make senses.

* downstream process -- from the previous point, we tried to check if the clusters make senses biologically by using functional enrichment analyses. 

One of limitations of this selection process and the whole pipeline is that fuctional enrichment analysis and motif discovery programs require adequate cluster sizes. Size is very important here.

**complexheatmap** This package was coded to work in object oriented fashion, allowing complex labels and annotations.
```{r}
source("https://bioconductor.org/biocLite.R")
biocLite("ComplexHeatmap")
```
```{r}
installed.packages("circlize")
```
```{r}
library(circlize)

```

```{r}
library(ComplexHeatmap)
```


```{r}
paste0(deparse(substitute(table_142.WardD2clust))," Overview")
```


```{r}
fast_heatmap<-function(presented_table,hclust_object,cluster_table){
#fix pallet
pallet<-c("#D7DE9F", "#7FE36F", "#DF8851", "#7BADD7", "#C34AE0", "#D49FDB", "#D6DB52", "#7CE4CD","#D49E9F", "#7C9E76", "#DC5997", "#8271D5", "#D4DCDD")  
#column annotation
col_anno<-data.frame(col_anno_1=colnames(presented_table),stringsAsFactors = F)
col_anno[1:9,1]<-"heatshock"
col_anno[10:19,1]<-"osmoticshock"
col_anno[20:28,1]<-"menadione"
col_anno[29:34,1]<-"ddt"
col_anno[35:42,1]<-"diamide"
col_anno[43:49,1]<-"sorbital"
col_anno[50:54,1]<-"aminoacidstravation"
col_anno[55:64,1]<-"nitrogendepletion"
col_anno[65:71,1]<-"diauxicshift"
col_anno[72:81,1]<-"stationaryphase"
col_anno[82:86,1]<-"continuouscarbonsources"
col_anno[87:92,1]<-"continuoustemperatures"
col_anno$col_anno_1<-as.factor(col_anno$col_anno_1)
#make ComplexHeatmap object from column annotation
col_anno_object<-HeatmapAnnotation(col_anno, col= list(col_anno_1=
  c(
    "heatshock"= pallet[1],
    "osmoticshock"= pallet[2],
    "menadione"= pallet[3],
    "ddt"= pallet[4],
    "diamide"= pallet[5],
    "sorbital"= pallet[6],
    "aminoacidstravation"= pallet[7],
    "nitrogendepletion"= pallet[8],
    "diauxicshift"= pallet[9],
    "stationaryphase"= pallet[10],
    "continuouscarbonsources"= pallet[11],
    "continuoustemperatures"= pallet[12]
  )
),
annotation_legend_param = list(col_anno_1 = list(nrow = 3, title_position = "leftcenter")), width = unit(5, "mm")
)
#Annotate the row with 8th cluster to give an overview on clustering method.
cluster_anno_8<-data.frame(cluster_anno_8=cluster_table[,8])
row_annotated<-rowAnnotation(cluster_anno_8)
#create complexheat mapobject
heatmap_object_1=Heatmap(presented_table,
        #original table
        column_title = paste0(deparse(substitute(hclust_object))," Overview"),
        cluster_rows = hclust_object, cluster_columns = FALSE, 
        #insert clustering results here
        split = 2,
        #splitting the cluster
        col = colorRamp2(c(-8, 0, 8), c("green", "black", "red")),
        #legend color
        show_row_dend = FALSE,
        #hide dendrogram
        heatmap_legend_param = list(title = "fold"),
        top_annotation = col_anno_object,
        
        show_row_names = FALSE, show_column_names = FALSE)
#show heatmap
draw(heatmap_object_1+row_annotated, annotation_legend_side="bottom")
}
```

```{r}
fast_heatmap(init_table_94.mat,table_142.WardD2clust,WardD2.cluster_table)
```

```{r}
fast_heatmap(init_table_94.mat,table_142.UPGMAclust,UPGMA.cluster_table)

```

```{r}
fast_heatmap(init_table_94.mat,table_142.WPGMAclust,WPGMA.cluster_table)
```


```{r}
fast_heatmap(init_table_94.mat,table_142.eisenclust,Eisen.cluster_table)
```

###CLUSTER ANALYSIS: GO ENRICHMENT

The previous step gives us visual overviews of clustering results, which are easy to read. We can see which method gives very small cluster and might not be suitable for the downstream pipeline, which requires cluster with adequate members. To actually determine whether those clusters have biological meaning or not, we need another tool. 

The idea of this step is:

* GO enrichment implies shared functional roles of genes in a cluster (=biological meaning)

* In motif discovery process, a cluster too large might undermine some motif

* So, we want to find a clustering method that can provide the number of cluster as many as possible (divide the table into small clusters as much as possible) while all of the cluster still have biological meaning 

In this work we use GO enrichment analyses tool, *GOsummaries*, which uses the *gProfileR* to analyse input data and visualise the results in easy-to-read figure.


```{r}
## try http:// if https:// URLs are not supported
#source("https://bioconductor.org/biocLite.R")
#biocLite("GOsummaries")
```
```{r}
#install.packages("rlist")
```

```{r}
library(gProfileR)
library(GOsummaries)
library(rlist)
```

To find the number mentioned earlier, I created a function which reads cluster table from previous step, iterates through each cluster number, seperate gene list into clusters as specified in the table, then feeds the gene group into gProfiler and GOsummeries for analysis and visualisation.

define function
```{r}
Gprofiler_enrichment<-function(cluster_table){
  #get column names
  cluster_colnames<-colnames(cluster_table)
  cluster_colnames<-grep(pattern = "cluster", cluster_colnames, value=TRUE)
  for(i in cluster_colnames){
    cluster_number<-unlist(strsplit(i,"_"))
    #create subdirectory
    mainsubdir<-paste0("./",dir_name,"/",deparse(substitute(cluster_table)))
    if(!file.exists(mainsubdir)){
      dir.create(mainsubdir)
    }
    sub_dir<-paste0("./",dir_name,"/",deparse(substitute(cluster_table)),"/cluster_",cluster_number[2])
    dir.create(sub_dir)
    #build containers
    cluster.list<-ls()
    GO.profile<-NA
    #loop for subcluster
    print(paste0("cluster number: ",cluster_number[2]))
    for(j in 1:as.numeric(cluster_number[2])){
        #GO analysis loop
        #pull gene list from rownames of the table
        temp.table<-cluster_table %>% rownames_to_column( var = "gene")%>%filter(UQ(as.name(i)) == j) %>% select(gene)
        temp.vector<-unname(unlist(temp.table))
        temp.profile<-gprofiler(temp.vector, organism = "scerevisiae")
        write.table(temp.profile, file=paste0(sub_dir,"/cluster_",j,"_in_",cluster_number[2],"_GOp.txt"), sep="\t")
        #GOchart loop
        if(j==1){
            cluster.list<-list(temp.vector)
          }else{
            cluster.list<-list.append(cluster.list,temp.vector)
          }
        }
  GO_sum.tmp<-gosummaries(cluster.list, organism = "scerevisiae",max_p_value = 0.05)
  plot(GO_sum.tmp, fontsize = 4, filename = paste0(sub_dir,"/cluster_",j,"_in_",cluster_number[2],"_GO_chart.png"),panel_height=1, components=1:length(GO_sum.tmp))  
}
}
```

Create directory for storing all the file
```{r}
dir_name<-paste("GO_1025")
dir.create(dir_name)
```

```{r}
Gprofiler_enrichment(UPGMA.cluster_table)
Gprofiler_enrichment(WPGMA.cluster_table)
Gprofiler_enrichment(WardD2.cluster_table)
Gprofiler_enrichment(Eisen.cluster_table)

```


Here are the highest number of cluster that pass the requirement.

UPGMA: 2 clusters
![UPGMA](GO_1025/UPGMA.cluster_table/cluster_2/cluster_2_in_2_GO_chart.png)

WPGMA: 10 clusters
![WPGMA](GO_1025/WPGMA.cluster_table/cluster_10/cluster_10_in_10_GO_chart.png)

Ward.D2: 19 clusters
![Ward](GO_1025/WardD2.cluster_table/cluster_19/cluster_19_in_19_GO_chart.png)

Eisen: 3 clusters
![Eisen](GO_1025/Eisen.cluster_table/cluster_3/cluster_3_in_3_GO_chart.png)

Please note that, the Eisen clustering method, which was used in the original publication, did not worked well with the way we define cluster. This leads to the assumption that the authors of orginal paper handpicked gene clusters of interest. In contrast, this work try to cover whole genome level, therefore, we will chose WARD.D2 at 19 cluster as an example.

####Separate whole sequences files into clusters

After we get the clustering method and the number of cluster we need, next we will create material for motif discovery. The input for motif discovery program is a set DNA/RNA/AA sequences. In this works, we will download flank-coding region sequences of yeast gene from biomart and them seperate those sequences by the gene cluster from the previous step.

flank-coding FASTA (1 files) ---(function)----> flank-coding cluster1 FASTA + flank-coding cluster2 FASTA + ... 

*Biostrings* reads FASTA file and store the sequences in stringset objects, which works like a table. Can be used to export FASTA file
```{r message=FALSE, warning=FALSE}
source("https://bioconductor.org/biocLite.R")
biocLite("Biostrings")
```
*biomaRt* connects to biomart and make a query for DNA sequences
```{r}
biocLite("biomaRt")
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(Biostrings)
library(biomaRt)
```

Prepare DNA sequences

We will use scerevisiae_gene_ensembl dataset
```{r}
ensembl = useMart("ensembl",dataset="scerevisiae_gene_ensembl")
```

Needed attribute:

*Gene stable ID :ensembl_gene_id

*Transcript ID :ensembl_transcript_id

*Flank coding region :coding_gene_flank

*Upstream/downstream flank :upstream_flank/downstream_flank

*Gene type :biotype

```{r}
chrom_list=c("I","II","III","IV","IX","V","VI","VII","VIII","X","XI","XII","XIII","XIV","XV","XVI")

#getBM() will fetch the data from BioMart, with this setup, we can get sequences of interest
up_500<-getBM(c("coding_gene_flank", "ensembl_gene_id"), filters = c("biotype", "upstream_flank","chromosome_name"), values = list("protein_coding", 500, chrom_list), mart = ensembl, checkFilters = FALSE)
down_500<-getBM(c("coding_gene_flank", "ensembl_gene_id"), filters = c("biotype", "downstream_flank","chromosome_name"), values = list("protein_coding", 500, chrom_list), mart = ensembl, checkFilters = FALSE)
```


define function
```{r}
#This part is for creating folder to store FASTA files
separate_into_cluster<-function(sequence_table, cluster_table, cluster_number,dir_name){
if(!file.exists(dir_name)){
      dir.create(dir_name)
}
sub_dir<-paste0("./",dir_name,"/cluster_",cluster_number)
if(!file.exists(sub_dir)){
      dir.create(sub_dir)
}
#loop from cluster 1 to maximum number
for(j in 1:cluster_number){
#create gene list by using cluster number
        gene_in_cluster<-cluster_table%>% dplyr::select(paste0("cluster_",cluster_number))%>% rownames_to_column(var="gene")%>%filter(UQ(as.name(paste0("cluster_",cluster_number)))==j)
#merge with genome-level sequence table      
      cluster_seq<-left_join(gene_in_cluster,sequence_table,by=c("gene"="ensembl_gene_id"))%>% na.omit()
#print out FASTA file      
      output_tab<-cluster_seq%>%pull(coding_gene_flank)%>%DNAStringSet()
      names(output_tab)<-cluster_seq$gene
      region_vector<-unlist(strsplit(deparse(substitute(sequence_table)),"_"))[1]
      tab_name<-paste0(sub_dir,"/cluster_",j,"_in_",cluster_number,"_",region_vector,".fasta")
      writeXStringSet(output_tab, tab_name, format="fasta")
      
    }
    print(paste0("cluster_",cluster_number," done."))
}

```

```{r}
separate_into_cluster(up_500,WardD2.cluster_table,19,"cluster_1025_Ward")
separate_into_cluster(down_500,WardD2.cluster_table,19,"cluster_1025_Ward")

```
